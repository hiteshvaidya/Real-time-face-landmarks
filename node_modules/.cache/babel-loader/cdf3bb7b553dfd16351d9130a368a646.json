{"ast":null,"code":"var _jsxFileName = \"/Users/hitesh/Documents/machine learning/facemesh/src/App.js\",\n    _s = $RefreshSig$();\n\n// useRef allows to have reference to canvas and webcam components\nimport React, { useRef, useEffect } from \"react\"; // import logo from './logo.svg';\n\nimport './App.css';\nimport * as tf from \"@tensorflow/tfjs\"; // import model\n\nimport * as facemesh from \"@tensorflow-models/face-landmarks-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawMesh } from \"./utilities\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  // setup references\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null); // Load model\n\n  const runFacemesh = async () => {\n    // OLD MODEL\n    // const net = await facemesh.load({\n    //   inputResolution: { width: 640, height: 480 },\n    //   scale: 0.8,\n    // });\n    // NEW MODEL\n    const net = await facemesh.load(facemesh.SupportedPackages.mediapipeFacemesh);\n    setInterval(() => {\n      detect(net);\n    }, 10);\n  }; // detect function\n  // net is our neural network from tfjs \n\n\n  const detect = async net => {\n    if ( // checks whether webcam is up and running and receiving data\n    typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight; // Set video width\n\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight; // Set canvas width\n\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight; // Make Detections\n      // OLD MODEL\n      //       const face = await net.estimateFaces(video);\n      // NEW MODEL\n\n      const face = await net.estimateFaces({\n        input: video\n      });\n      console.log(face); // Get canvas context\n\n      const ctx = canvasRef.current.getContext(\"2d\");\n      requestAnimationFrame(() => {\n        drawMesh(face, ctx);\n      });\n    }\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: [/*#__PURE__*/_jsxDEV(Webcam, {\n        ref: webcamRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zindex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 70,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zindex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 85,\n        columnNumber: 13\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 69,\n      columnNumber: 9\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 68,\n    columnNumber: 7\n  }, this);\n}\n\n_s(App, \"AwQWgsmsPhWgADiRou0jnDEtoH4=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/hitesh/Documents/machine learning/facemesh/src/App.js"],"names":["React","useRef","useEffect","tf","facemesh","Webcam","drawMesh","App","webcamRef","canvasRef","runFacemesh","net","load","SupportedPackages","mediapipeFacemesh","setInterval","detect","current","video","readyState","videoWidth","videoHeight","width","height","face","estimateFaces","input","console","log","ctx","getContext","requestAnimationFrame","position","marginLeft","marginRight","left","right","textAlign","zindex"],"mappings":";;;AAAA;AACA,OAAOA,KAAP,IAAeC,MAAf,EAAuBC,SAAvB,QAAuC,OAAvC,C,CACA;;AACA,OAAO,WAAP;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB,C,CAEA;;AACA,OAAO,KAAKC,QAAZ,MAA0B,6CAA1B;AACA,OAAOC,MAAP,MAAmB,cAAnB;AACA,SAASC,QAAT,QAAyB,aAAzB;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb;AACA,QAAMC,SAAS,GAAGP,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMQ,SAAS,GAAGR,MAAM,CAAC,IAAD,CAAxB,CAHa,CAKb;;AACE,QAAMS,WAAW,GAAG,YAAY;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,UAAMC,GAAG,GAAG,MAAMP,QAAQ,CAACQ,IAAT,CAAcR,QAAQ,CAACS,iBAAT,CAA2BC,iBAAzC,CAAlB;AACAC,IAAAA,WAAW,CAAC,MAAM;AACdC,MAAAA,MAAM,CAACL,GAAD,CAAN;AACH,KAFU,EAER,EAFQ,CAAX;AAGH,GAXD,CANW,CAmBX;AACA;;;AACA,QAAMK,MAAM,GAAG,MAAOL,GAAP,IAAe;AAC1B,SACI;AACA,WAAOH,SAAS,CAACS,OAAjB,KAA6B,WAA7B,IACAT,SAAS,CAACS,OAAV,KAAsB,IADtB,IAEAT,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAJ3C,EAKE;AACE;AACA,YAAMD,KAAK,GAAGV,SAAS,CAACS,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAGZ,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBE,UAA3C;AACA,YAAMC,WAAW,GAAGb,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBG,WAA5C,CAJF,CAME;;AACAb,MAAAA,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBI,KAAxB,GAAgCF,UAAhC;AACAZ,MAAAA,SAAS,CAACS,OAAV,CAAkBC,KAAlB,CAAwBK,MAAxB,GAAiCF,WAAjC,CARF,CAUE;;AACAZ,MAAAA,SAAS,CAACQ,OAAV,CAAkBK,KAAlB,GAA0BF,UAA1B;AACAX,MAAAA,SAAS,CAACQ,OAAV,CAAkBM,MAAlB,GAA2BF,WAA3B,CAZF,CAcE;AACA;AACA;AACA;;AACA,YAAMG,IAAI,GAAG,MAAMb,GAAG,CAACc,aAAJ,CAAkB;AAACC,QAAAA,KAAK,EAACR;AAAP,OAAlB,CAAnB;AACAS,MAAAA,OAAO,CAACC,GAAR,CAAYJ,IAAZ,EAnBF,CAqBE;;AACA,YAAMK,GAAG,GAAGpB,SAAS,CAACQ,OAAV,CAAkBa,UAAlB,CAA6B,IAA7B,CAAZ;AACAC,MAAAA,qBAAqB,CAAC,MAAI;AAACzB,QAAAA,QAAQ,CAACkB,IAAD,EAAOK,GAAP,CAAR;AAAoB,OAA1B,CAArB;AACH;AACJ,GA/BD;;AAkCF,sBACI;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,2BACE;AAAQ,MAAA,SAAS,EAAC,YAAlB;AAAA,8BACI,QAAC,MAAD;AACI,QAAA,GAAG,EAAErB,SADT;AAEI,QAAA,KAAK,EAAE;AACHwB,UAAAA,QAAQ,EAAE,UADP;AAEHC,UAAAA,UAAU,EAAE,MAFT;AAGHC,UAAAA,WAAW,EAAE,MAHV;AAIHC,UAAAA,IAAI,EAAE,CAJH;AAKHC,UAAAA,KAAK,EAAE,CALJ;AAMHC,UAAAA,SAAS,EAAE,QANR;AAOHC,UAAAA,MAAM,EAAE,CAPL;AAQHhB,UAAAA,KAAK,EAAE,GARJ;AASHC,UAAAA,MAAM,EAAE;AATL;AAFX;AAAA;AAAA;AAAA;AAAA,cADJ,eAgBI;AACI,QAAA,GAAG,EAAEd,SADT;AAEI,QAAA,KAAK,EAAE;AACHuB,UAAAA,QAAQ,EAAE,UADP;AAEHC,UAAAA,UAAU,EAAE,MAFT;AAGHC,UAAAA,WAAW,EAAE,MAHV;AAIHC,UAAAA,IAAI,EAAE,CAJH;AAKHC,UAAAA,KAAK,EAAE,CALJ;AAMHC,UAAAA,SAAS,EAAE,QANR;AAOHC,UAAAA,MAAM,EAAE,CAPL;AAQHhB,UAAAA,KAAK,EAAE,GARJ;AASHC,UAAAA,MAAM,EAAE;AATL;AAFX;AAAA;AAAA;AAAA;AAAA,cAhBJ;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,UADJ;AAmCD;;GA1FQhB,G;;KAAAA,G;AA4FT,eAAeA,GAAf","sourcesContent":["// useRef allows to have reference to canvas and webcam components\nimport React, {useRef, useEffect} from \"react\";\n// import logo from './logo.svg';\nimport './App.css';\nimport * as tf from \"@tensorflow/tfjs\";\n\n// import model\nimport * as facemesh from \"@tensorflow-models/face-landmarks-detection\";\nimport Webcam from \"react-webcam\";\nimport { drawMesh } from \"./utilities\";\n\nfunction App() {\n  // setup references\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  // Load model\n    const runFacemesh = async () => {\n        // OLD MODEL\n        // const net = await facemesh.load({\n        //   inputResolution: { width: 640, height: 480 },\n        //   scale: 0.8,\n        // });\n        // NEW MODEL\n        const net = await facemesh.load(facemesh.SupportedPackages.mediapipeFacemesh);\n        setInterval(() => {\n            detect(net);\n        }, 10);\n    };\n\n    // detect function\n    // net is our neural network from tfjs \n    const detect = async (net) => {\n        if (\n            // checks whether webcam is up and running and receiving data\n            typeof webcamRef.current !== \"undefined\" &&\n            webcamRef.current !== null &&\n            webcamRef.current.video.readyState === 4\n        ) {\n            // Get Video Properties\n            const video = webcamRef.current.video;\n            const videoWidth = webcamRef.current.video.videoWidth;\n            const videoHeight = webcamRef.current.video.videoHeight;\n\n            // Set video width\n            webcamRef.current.video.width = videoWidth;\n            webcamRef.current.video.height = videoHeight;\n\n            // Set canvas width\n            canvasRef.current.width = videoWidth;\n            canvasRef.current.height = videoHeight;\n\n            // Make Detections\n            // OLD MODEL\n            //       const face = await net.estimateFaces(video);\n            // NEW MODEL\n            const face = await net.estimateFaces({input:video});\n            console.log(face);\n\n            // Get canvas context\n            const ctx = canvasRef.current.getContext(\"2d\");\n            requestAnimationFrame(()=>{drawMesh(face, ctx)});\n        }\n    };\n\n\n  return (\n      <div className=\"App\">\n        <header className=\"App-header\">\n            <Webcam\n                ref={webcamRef}\n                style={{\n                    position: \"absolute\",\n                    marginLeft: \"auto\",\n                    marginRight: \"auto\",\n                    left: 0,\n                    right: 0,\n                    textAlign: \"center\",\n                    zindex: 9,\n                    width: 640,\n                    height: 480,\n                }}\n            />\n\n            <canvas\n                ref={canvasRef}\n                style={{\n                    position: \"absolute\",\n                    marginLeft: \"auto\",\n                    marginRight: \"auto\",\n                    left: 0,\n                    right: 0,\n                    textAlign: \"center\",\n                    zindex: 9,\n                    width: 640,\n                    height: 480,\n                }}\n            />\n        </header>\n      </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}